\documentclass[main]{subfiles}
\begin{document}
\section{Background and Notations}
This section gives a brief background about TCP and fixes notations and definitions used throughout the paper.

%\subsection{Transductive Conformity Prediction (TCP)}
%\section*{Notations and Assumptions}
The object space is denoted by $\mathcal{X} \in \mathbb{R}^p$, where $p$ is the number of features, and  label space is denoted by $\mathcal{Y} \in \{ 0,1 \}$. We assume that each observation consists of an object and its label, and its space is given as $\mathcal{Z} := \mathcal{X} \times \mathcal{Y}$. %are fixed throughout the article. 
The typical classification problem is, given a training dataset $Z = \{ z_1 , ..., z_n \} $ -- where $n$ is the number of observations in the training set, and each observation $z_i = (x_i, y_i)$ are labeled observations -- we want to predict the label of a new object $x_{new}$ whose label is unknown. We also assume the exchangeability of observations throughout the paper.
%First, we define a transductive non-conformity measure and transductive conformity score in the following.


The nonconformity measure is a function that measures the strangeness of an observation. Consider an example of non-conformity measure for binary classification
using  random forest method \cite{Breiman}, where voting for each class - 
the ratio between the number of trees in the forest voting for a given class divided by
the total number of tree - is computed as a 
conformity scores or probabilities for each data point. 
 %for example we consider the following non conformity measure for our computations. 
%\begin{definition} [Nonconformity Measure]
%A nonconformity measure is a measurable function $\mathcal{A} : \mathcal{Z} \times \mathcal{Z}  \rightarrow \mathbb{R}$ such that $\mathcal{A}(Z_1 , Z_2 )$ does not depend on the ordering of observations in the set $Z_1$. 
%\end{definition}

\begin{align} \label{eq:def_nonconformity}
\begin{split}
\alpha_i(z_i, 0) &= \frac{\#\text{trees voting for class 0}}{\#\text{of trees}}\\
\alpha_i(z_i, 1) &= \frac{\#\text{trees voting for class 1}}{\#\text{of trees}}
\end{split}
\end{align}

We denote by $\alpha_i(y)$ nonconformity score for $i^{th}$ observation for class $y$. Each component  $\alpha_i(y)$ that corresponds to the sample $(x_i,y_i)$ is computed by
euqation (\ref{eq:def_nonconformity}) based on the augmented sample  $\{ z_1 , ..., z_n, z_{n+1}=(x_{new},y) \}$. Then p-value as given below, \cite{vovk2005algorithmic},  describes the lack of conformity of the  new observation $x_{new}$ to the training set $Z$. 
 \begin{align*}
 p_0 &= \frac{| \{ z_i \in Z : y_i=0, \alpha_i(0) < \alpha_{new}(0) \} | + u* | \{ z_i \in Z : y_i=0, \alpha_i(0) = \alpha_{new}(0)\} |}{n_0+1} \\
 p_1 &= \frac{| \{ z_i \in Z :  y_i=1, \alpha_i(1) < \alpha_{new}(1) \}  |+u*|  \{ z_i \in Z :  y_i=1, \alpha_i(1) =\alpha_{new}(1) \} |}{n_1+1} ,
 \end{align*}
 where $u \sim U[0,1]$, $n_0$ denotes the number of observations having the true label as class0, and $n_1$ denotes the number of observations having the true label as class1.
The p-value $p(y)=p_y, y \in Y$ lies in $ \left( \frac{1}{n_y+1},1 \right)$. The smaller the $p(y)$
 is, the less likely the true pair is $(x_{new},y)$.

 
Conformal prediction~\citep{vovk2005algorithmic} exists on top of an existing machine learning method and uses available data to determine valid prediction regions for new objects. 
%The  conformal  predictors  exist  on  top  of  standard  machine  learning methods that results in prediction sets for all confidence levels. 
%The nonconformity measure is a function that measures the strangeness of an observation,which is used to improve the performance of the prediction algorithms. 
The predicted region of an observation is a subset of $\mathcal{Y}$ , denoted as $\Gamma^{\epsilon} = \{ y \mid p_y > \epsilon \}$, at a significance level $\alpha$. In transductive approach (Algorithm \ref{algo:TCP}), the underlying model must be retrained each time a new test object is obtained. For further details on TCP, we refer to \cite{vapnik1998statistical}, \cite{shafer2008tutorial}, \cite{vovk2005algorithmic} and \cite{balasubramanian2014conformal}. 



\begin{algorithm}[H]
 \caption{\textbf{TCP}} \label{algo:TCP}
 \textbf{Input:}{ (training dataset:$Z$, test data:$x_{new}$, label set:$Y$, a nonconformity measure:$\mathcal{A})$}\\
 \textbf{Output:}{\textbf{ p-values} }\\
 %\textbf{Initialization\;}
 \For{each $y \in \mathcal{Y}$ }{
 	$z_{n+1} = (x_{new},y) $;\\
 	$Z^* = (Z,z_{n+1})$ ;\\
 	Compute the transductive nonconformity scores:\\
 	 $\alpha_i = \mathcal{A}(Z^*, z_i)$ for each $z_i \in Z^*$;\\
 	 \textbf{\\}
	Compute p-value: $ p(y) = \frac{| \{ i \in \{1,..,n+1\} : y_i=y, \alpha_i(y) < \alpha_{new}(y) \} | + u*| \{ i \in \{1,..,n+1\} : y_i=y, \alpha_i(y) < \alpha_{new}(y) \} |}{n_y}$;\\
  }

 $\textbf{p-values} = \{ p(y)| y \in \mathcal{Y}\}$;\\
 \textbf{return \textbf{p-values}};\\
 \end{algorithm}
 \vspace{10pt}
\textbf{ \\}

%The significance is assumed at $\alpha = 0.05$, so we drop the superscript from $\Gamma$ from now on wards. The predictor make an error when it predicts an empty prediction region for a test case $|\Gamma| = 0$.
 
We consider the following three criterion that measures the quality of a TCP: error rate,
validity and efficiency. A predictor makes an error when the predicted region does not contain the true label $ y \not\in \Gamma^{\epsilon}$. Given a training dataset $Z$ and an external test set $T$,  and $|T| = m$. Suppose that the TCP gives prediction regions as $\Gamma_1^{\epsilon}, ...., \Gamma_m^{\epsilon}$, then the error rate is defined as follows.

\begin{definition}[Error rate]
\begin{align} \label{eq:errorRate}
		ER^{\epsilon} &= \frac{ 1}{m} \sum\limits_{i=1}^{m} \textbf{I}_{ \{y_i \not\in \Gamma_i^{\epsilon} \} },		
\end{align}	
where $y_i$ is the true class label of the $i^{th}$ test case and $\textbf{I}$ is an indicator function. 	
\end{definition}
%&\frac{\# of errors}{m}
In the following, we consider a way of assessing validity of a TCP in terms of deviation of observed from expected error. The deviation from exact validity can be computed as (\cite{carlsson2017comparing}) the Euclidean norm of the difference of the observed error and the expected error for a given set of predefined significance levels. Let us assume a set of significance levels $\epsilon = \{ \epsilon_1, ..., \epsilon_k \}$, then the formula for the validity can be given as follows.

\begin{definition}[Validity]
\begin{align} \label{eq:validity}
		VAL = \sqrt{ \sum\limits_{i=1}^{k} (ER^{\epsilon_i} -\epsilon_i)^2 }
\end{align}	 
\end{definition}
%We note that TCPs are valid in the sense error rate is less than equal to the significance level, or equivalently the observed error is less than equal to the expected error.


We use obsered fuzziness, \cite{vovk2016criteria}, as our measure of efficiency . The Observed fuzziness is defined as the sum of all p-values for the incorrect class labels. %For example, for binary classification the efficiency can be computed as follows.
\begin{definition}[Efficiency]
\begin{align} \label{eq:efficiency}
	EFF =\frac{ 1}{m} \sum\limits_{i=1}^{m} \sum\limits_{y_i \neq y }  p_i^y,		
\end{align}
\end{definition}
We note that for the above measure of validity and efficiency, smaller
values are preferable.

\end{document}